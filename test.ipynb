{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cf0d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14bf887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (3802, 128, 128, 3) (3802, 5) (3802, 4)\n",
      "Test  : (951, 128, 128, 3) (951, 5) (951, 4)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data_all\"\n",
    "IMG_SIZE = 128\n",
    "\n",
    "fruit_classes = [\"ananas\", \"banane\", \"tomate\", \"papaye\", \"non_fruit\"]\n",
    "maturity_classes = [\"pas_mur\", \"mur\", \"trop_mur\"]\n",
    "\n",
    "X = []\n",
    "y_fruit = []\n",
    "y_maturity = []\n",
    "\n",
    "\n",
    "for fruit in fruit_classes:\n",
    "    fruit_path = os.path.join(DATA_DIR, fruit)\n",
    "    if not os.path.isdir(fruit_path):\n",
    "        continue\n",
    "\n",
    "    if fruit == \"non_fruit\":\n",
    "        files = [f for f in os.listdir(fruit_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        for filename in files:\n",
    "            img_path = os.path.join(fruit_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = img / 255.0\n",
    "\n",
    "            X.append(img)\n",
    "            y_fruit.append(fruit)\n",
    "            y_maturity.append(3)\n",
    "        continue\n",
    "\n",
    "    for subdir in os.listdir(fruit_path):\n",
    "        subdir_path = os.path.join(fruit_path, subdir)\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "\n",
    "        files = [f for f in os.listdir(subdir_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        for filename in files:\n",
    "            img_path = os.path.join(subdir_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = img / 255.0\n",
    "\n",
    "            X.append(img)\n",
    "            y_fruit.append(fruit)\n",
    "\n",
    "            if subdir in maturity_classes:\n",
    "                y_maturity.append(maturity_classes.index(subdir))\n",
    "            else:\n",
    "                y_maturity.append(3)\n",
    "\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "fruit_indices = [fruit_classes.index(f) for f in y_fruit]\n",
    "y_fruit = to_categorical(fruit_indices, num_classes=len(fruit_classes))\n",
    "\n",
    "y_maturity = to_categorical(y_maturity, num_classes=len(maturity_classes)+1)\n",
    "maturity_mask = (np.argmax(y_maturity, axis=1) != 3).astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_fruit_train, y_fruit_test, y_maturity_train, y_maturity_test, mask_train, mask_test = train_test_split(\n",
    "    X, y_fruit, y_maturity, maturity_mask, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train :\", X_train.shape, y_fruit_train.shape, y_maturity_train.shape)\n",
    "print(\"Test  :\", X_test.shape, y_fruit_test.shape, y_maturity_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd39fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_21… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_22… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_23    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_23… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,864</span> │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fruit_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ maturity_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_21… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_22… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_23    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_23… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m8,388,864\u001b[0m │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fruit_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m1,285\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ maturity_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m1,028\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,484,425</span> (32.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,484,425\u001b[0m (32.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,484,425</span> (32.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,484,425\u001b[0m (32.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - fruit_output_accuracy: 0.8732 - fruit_output_loss: 0.4113 - loss: 1.2245 - maturity_output_accuracy: 0.6610 - maturity_output_loss: 0.8132\n",
      "Epoch 1: val_loss improved from None to 0.39372, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 312ms/step - fruit_output_accuracy: 0.9477 - fruit_output_loss: 0.1915 - loss: 0.7823 - maturity_output_accuracy: 0.7733 - maturity_output_loss: 0.5908 - val_fruit_output_accuracy: 0.9853 - val_fruit_output_loss: 0.0502 - val_loss: 0.3937 - val_maturity_output_accuracy: 0.8759 - val_maturity_output_loss: 0.3457\n",
      "Epoch 2/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - fruit_output_accuracy: 0.9831 - fruit_output_loss: 0.0606 - loss: 0.4021 - maturity_output_accuracy: 0.8777 - maturity_output_loss: 0.3415\n",
      "Epoch 2: val_loss improved from 0.39372 to 0.26354, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 320ms/step - fruit_output_accuracy: 0.9866 - fruit_output_loss: 0.0511 - loss: 0.3875 - maturity_output_accuracy: 0.8801 - maturity_output_loss: 0.3360 - val_fruit_output_accuracy: 0.9926 - val_fruit_output_loss: 0.0172 - val_loss: 0.2635 - val_maturity_output_accuracy: 0.9096 - val_maturity_output_loss: 0.2465\n",
      "Epoch 3/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - fruit_output_accuracy: 0.9920 - fruit_output_loss: 0.0260 - loss: 0.2694 - maturity_output_accuracy: 0.9118 - maturity_output_loss: 0.2434\n",
      "Epoch 3: val_loss improved from 0.26354 to 0.25381, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 326ms/step - fruit_output_accuracy: 0.9913 - fruit_output_loss: 0.0280 - loss: 0.2744 - maturity_output_accuracy: 0.9114 - maturity_output_loss: 0.2463 - val_fruit_output_accuracy: 0.9958 - val_fruit_output_loss: 0.0139 - val_loss: 0.2538 - val_maturity_output_accuracy: 0.9085 - val_maturity_output_loss: 0.2385\n",
      "Epoch 4/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - fruit_output_accuracy: 0.9953 - fruit_output_loss: 0.0174 - loss: 0.2567 - maturity_output_accuracy: 0.9086 - maturity_output_loss: 0.2393\n",
      "Epoch 4: val_loss improved from 0.25381 to 0.21475, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 310ms/step - fruit_output_accuracy: 0.9958 - fruit_output_loss: 0.0170 - loss: 0.2587 - maturity_output_accuracy: 0.9072 - maturity_output_loss: 0.2416 - val_fruit_output_accuracy: 0.9989 - val_fruit_output_loss: 0.0051 - val_loss: 0.2148 - val_maturity_output_accuracy: 0.9201 - val_maturity_output_loss: 0.2083\n",
      "Epoch 5/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - fruit_output_accuracy: 0.9946 - fruit_output_loss: 0.0179 - loss: 0.2103 - maturity_output_accuracy: 0.9252 - maturity_output_loss: 0.1924\n",
      "Epoch 5: val_loss improved from 0.21475 to 0.21096, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 328ms/step - fruit_output_accuracy: 0.9945 - fruit_output_loss: 0.0170 - loss: 0.2161 - maturity_output_accuracy: 0.9208 - maturity_output_loss: 0.1992 - val_fruit_output_accuracy: 1.0000 - val_fruit_output_loss: 0.0076 - val_loss: 0.2110 - val_maturity_output_accuracy: 0.9317 - val_maturity_output_loss: 0.2022\n",
      "Epoch 6/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - fruit_output_accuracy: 0.9979 - fruit_output_loss: 0.0091 - loss: 0.1887 - maturity_output_accuracy: 0.9395 - maturity_output_loss: 0.1796\n",
      "Epoch 6: val_loss did not improve from 0.21096\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 314ms/step - fruit_output_accuracy: 0.9974 - fruit_output_loss: 0.0096 - loss: 0.1894 - maturity_output_accuracy: 0.9337 - maturity_output_loss: 0.1800 - val_fruit_output_accuracy: 1.0000 - val_fruit_output_loss: 0.0042 - val_loss: 0.2735 - val_maturity_output_accuracy: 0.8991 - val_maturity_output_loss: 0.2680\n",
      "Epoch 7/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - fruit_output_accuracy: 0.9982 - fruit_output_loss: 0.0086 - loss: 0.1841 - maturity_output_accuracy: 0.9379 - maturity_output_loss: 0.1755\n",
      "Epoch 7: val_loss improved from 0.21096 to 0.19294, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 318ms/step - fruit_output_accuracy: 0.9968 - fruit_output_loss: 0.0148 - loss: 0.1874 - maturity_output_accuracy: 0.9342 - maturity_output_loss: 0.1730 - val_fruit_output_accuracy: 0.9989 - val_fruit_output_loss: 0.0050 - val_loss: 0.1929 - val_maturity_output_accuracy: 0.9327 - val_maturity_output_loss: 0.1868\n",
      "Epoch 8/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - fruit_output_accuracy: 0.9986 - fruit_output_loss: 0.0117 - loss: 0.1578 - maturity_output_accuracy: 0.9496 - maturity_output_loss: 0.1462\n",
      "Epoch 8: val_loss did not improve from 0.19294\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 307ms/step - fruit_output_accuracy: 0.9989 - fruit_output_loss: 0.0080 - loss: 0.1586 - maturity_output_accuracy: 0.9450 - maturity_output_loss: 0.1506 - val_fruit_output_accuracy: 1.0000 - val_fruit_output_loss: 9.2695e-04 - val_loss: 0.2451 - val_maturity_output_accuracy: 0.9138 - val_maturity_output_loss: 0.2425\n",
      "Epoch 9/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - fruit_output_accuracy: 0.9982 - fruit_output_loss: 0.0080 - loss: 0.1527 - maturity_output_accuracy: 0.9431 - maturity_output_loss: 0.1447\n",
      "Epoch 9: val_loss improved from 0.19294 to 0.18933, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 310ms/step - fruit_output_accuracy: 0.9976 - fruit_output_loss: 0.0076 - loss: 0.1439 - maturity_output_accuracy: 0.9511 - maturity_output_loss: 0.1362 - val_fruit_output_accuracy: 1.0000 - val_fruit_output_loss: 0.0018 - val_loss: 0.1893 - val_maturity_output_accuracy: 0.9411 - val_maturity_output_loss: 0.1863\n",
      "Epoch 10/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - fruit_output_accuracy: 0.9994 - fruit_output_loss: 0.0028 - loss: 0.1187 - maturity_output_accuracy: 0.9553 - maturity_output_loss: 0.1159\n",
      "Epoch 10: val_loss did not improve from 0.18933\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 310ms/step - fruit_output_accuracy: 0.9992 - fruit_output_loss: 0.0029 - loss: 0.1343 - maturity_output_accuracy: 0.9495 - maturity_output_loss: 0.1316 - val_fruit_output_accuracy: 0.9989 - val_fruit_output_loss: 0.0053 - val_loss: 0.2130 - val_maturity_output_accuracy: 0.9201 - val_maturity_output_loss: 0.2073\n",
      "Epoch 11/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - fruit_output_accuracy: 0.9996 - fruit_output_loss: 0.0034 - loss: 0.1228 - maturity_output_accuracy: 0.9577 - maturity_output_loss: 0.1194\n",
      "Epoch 11: val_loss improved from 0.18933 to 0.18302, saving model to fruit_maturity_detector.keras\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 333ms/step - fruit_output_accuracy: 0.9992 - fruit_output_loss: 0.0037 - loss: 0.1317 - maturity_output_accuracy: 0.9563 - maturity_output_loss: 0.1280 - val_fruit_output_accuracy: 1.0000 - val_fruit_output_loss: 0.0031 - val_loss: 0.1830 - val_maturity_output_accuracy: 0.9295 - val_maturity_output_loss: 0.1791\n",
      "Epoch 12/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - fruit_output_accuracy: 0.9993 - fruit_output_loss: 0.0032 - loss: 0.1024 - maturity_output_accuracy: 0.9628 - maturity_output_loss: 0.0992\n",
      "Epoch 12: val_loss did not improve from 0.18302\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 345ms/step - fruit_output_accuracy: 0.9992 - fruit_output_loss: 0.0034 - loss: 0.1014 - maturity_output_accuracy: 0.9637 - maturity_output_loss: 0.0980 - val_fruit_output_accuracy: 0.9979 - val_fruit_output_loss: 0.0058 - val_loss: 0.2060 - val_maturity_output_accuracy: 0.9348 - val_maturity_output_loss: 0.1991\n",
      "Epoch 13/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - fruit_output_accuracy: 0.9980 - fruit_output_loss: 0.0035 - loss: 0.0870 - maturity_output_accuracy: 0.9665 - maturity_output_loss: 0.0835\n",
      "Epoch 13: val_loss did not improve from 0.18302\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 311ms/step - fruit_output_accuracy: 0.9987 - fruit_output_loss: 0.0034 - loss: 0.0938 - maturity_output_accuracy: 0.9666 - maturity_output_loss: 0.0904 - val_fruit_output_accuracy: 0.9968 - val_fruit_output_loss: 0.0053 - val_loss: 0.2175 - val_maturity_output_accuracy: 0.9327 - val_maturity_output_loss: 0.2111\n",
      "Epoch 14/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - fruit_output_accuracy: 0.9992 - fruit_output_loss: 0.0034 - loss: 0.0971 - maturity_output_accuracy: 0.9678 - maturity_output_loss: 0.0938\n",
      "Epoch 14: val_loss did not improve from 0.18302\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 316ms/step - fruit_output_accuracy: 0.9992 - fruit_output_loss: 0.0029 - loss: 0.0993 - maturity_output_accuracy: 0.9645 - maturity_output_loss: 0.0966 - val_fruit_output_accuracy: 0.9989 - val_fruit_output_loss: 0.0047 - val_loss: 0.3128 - val_maturity_output_accuracy: 0.9054 - val_maturity_output_loss: 0.3066\n",
      "Epoch 15/15\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - fruit_output_accuracy: 0.9991 - fruit_output_loss: 0.0037 - loss: 0.0997 - maturity_output_accuracy: 0.9612 - maturity_output_loss: 0.0960\n",
      "Epoch 15: val_loss did not improve from 0.18302\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 307ms/step - fruit_output_accuracy: 0.9989 - fruit_output_loss: 0.0039 - loss: 0.0909 - maturity_output_accuracy: 0.9637 - maturity_output_loss: 0.0869 - val_fruit_output_accuracy: 0.9979 - val_fruit_output_loss: 0.0059 - val_loss: 0.2162 - val_maturity_output_accuracy: 0.9359 - val_maturity_output_loss: 0.2086\n",
      "Modèle sauvegardé dans fruit_maturity_detector.keras\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "IMG_SIZE = 128\n",
    "num_fruit_classes = 5\n",
    "num_maturity_classes = 3\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "fruit_output = Dense(num_fruit_classes, activation='softmax', name='fruit_output')(x)\n",
    "\n",
    "maturity_output = Dense(num_maturity_classes + 1, activation='softmax', name='maturity_output')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[fruit_output, maturity_output])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'fruit_output': 'categorical_crossentropy',\n",
    "        'maturity_output': 'categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'fruit_output': 'accuracy',\n",
    "        'maturity_output': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"fruit_maturity_detector.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\n",
    "        'fruit_output': y_fruit_train,\n",
    "        'maturity_output': y_maturity_train\n",
    "    },\n",
    "    validation_data=(\n",
    "        X_test,\n",
    "        {\n",
    "            'fruit_output': y_fruit_test,\n",
    "            'maturity_output': y_maturity_test\n",
    "        }\n",
    "    ),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint]  \n",
    ")\n",
    "\n",
    "\n",
    "# model.save(\"fruit_maturity_detector.keras\")\n",
    "\n",
    "print(\"Modèle sauvegardé dans fruit_maturity_detector.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07d5e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - fruit_output_accuracy: 0.9979 - fruit_output_loss: 0.0059 - loss: 0.2162 - maturity_output_accuracy: 0.9359 - maturity_output_loss: 0.2086\n",
      "Résultats de l'évaluation : [0.21615181863307953, 0.005924052558839321, 0.20861075818538666, 0.9978969693183899, 0.9358569979667664]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(\n",
    "    X_test,\n",
    "    {\n",
    "        'fruit_output': y_fruit_test,\n",
    "        'maturity_output': y_maturity_test\n",
    "    },\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Résultats de l'évaluation :\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac7b89c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step\n",
      "[[ 15   0   0   0   0]\n",
      " [  0 493   0   1   0]\n",
      " [  0   0 392   1   0]\n",
      " [  0   0   0  47   0]\n",
      " [  0   0   0   0   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ananas       1.00      1.00      1.00        15\n",
      "      banane       1.00      1.00      1.00       494\n",
      "      tomate       1.00      1.00      1.00       393\n",
      "      papaye       0.96      1.00      0.98        47\n",
      "   non_fruit       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       951\n",
      "   macro avg       0.99      1.00      1.00       951\n",
      "weighted avg       1.00      1.00      1.00       951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_fruit_test_labels = np.argmax(y_fruit_test, axis=1)\n",
    "y_fruit_pred_labels = np.argmax(model.predict(X_test)[0], axis=1)\n",
    "\n",
    "print(confusion_matrix(y_fruit_test_labels, y_fruit_pred_labels))\n",
    "print(classification_report(y_fruit_test_labels, y_fruit_pred_labels, target_names=fruit_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4dd403",
   "metadata": {},
   "source": [
    "TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f591440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Fruit prédit : banane\n",
      "Maturité prédite : mur\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"banane_mur.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (128, 128))\n",
    "img = img / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "pred_fruit, pred_maturity = model.predict(img)\n",
    "\n",
    "fruit_idx = np.argmax(pred_fruit)\n",
    "maturity_idx = np.argmax(pred_maturity)\n",
    "\n",
    "print(\"Fruit prédit :\", fruit_classes[fruit_idx])\n",
    "print(\"Maturité prédite :\", maturity_classes[maturity_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716874c9",
   "metadata": {},
   "source": [
    "TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea6286d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Image : tomate_mur.jpg → Fruit : tomate, Maturité : mur\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Image : banane_mur.jpg → Fruit : banane, Maturité : mur\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Image : non_fruit3.png → Ce n'est pas un fruit.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Image : non_fruit1.png → Ce n'est pas un fruit.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Image : 7_dos.jpg → Fruit : ananas, Maturité : mur\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Image : tomate_mur1.png → Fruit : tomate, Maturité : trop_mur\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Image : pas_mur.png → Fruit : banane, Maturité : trop_mur\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"fruit_maturity_detector.keras\"\n",
    "IMG_SIZE = 128\n",
    "\n",
    "fruit_classes = [\"ananas\", \"banane\", \"tomate\", \"papaye\", \"non_fruit\"]\n",
    "maturity_classes = [\"pas_mur\", \"mur\", \"trop_mur\"]\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Erreur : impossible de lire l'image {image_path}\")\n",
    "        return\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    pred_fruit, pred_maturity = model.predict(img)\n",
    "    fruit_idx = np.argmax(pred_fruit)\n",
    "    maturity_idx = np.argmax(pred_maturity)\n",
    "\n",
    "    if fruit_classes[fruit_idx] == \"non_fruit\":\n",
    "        print(f\"Image : {image_path} → Ce n'est pas un fruit.\")\n",
    "    else:\n",
    "        print(f\"Image : {image_path} → Fruit : {fruit_classes[fruit_idx]}, Maturité : {maturity_classes[maturity_idx]}\")\n",
    "\n",
    "predict_image(\"tomate_mur.jpg\")\n",
    "predict_image(\"banane_mur.jpg\")\n",
    "predict_image(\"non_fruit3.png\")\n",
    "predict_image(\"non_fruit1.png\")\n",
    "predict_image(\"7_dos.jpg\")\n",
    "\n",
    "predict_image(\"tomate_mur1.png\")\n",
    "# predict_image(\"papaye_mur.jpg\")\n",
    "predict_image(\"pas_mur.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba403276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\HP\\Desktop\\Rendu\\Semestre2\\C-DAT-900-ABJ-2-1-ecp-14\\pas_mur.png: 448x640 1 banana, 110.3ms\n",
      "Speed: 4.4ms preprocess, 110.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "results = model(\"pas_mur.png\")\n",
    "results[0].show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
