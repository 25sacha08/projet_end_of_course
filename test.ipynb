{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cf0d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset chargé :\n",
      "Images : (2457, 128, 128, 3)\n",
      "Labels : (2457,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model \n",
    "from keras.layers import MaxPooling2D, Flatten, Conv2D\n",
    "\n",
    "DATASET_PATH = \"data/\"\n",
    "categories = [\"pas_mur\", \"mur\", \"trop_mur\"]\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    folder = os.path.join(DATASET_PATH, category)\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, file)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "\n",
    "        data.append(img)\n",
    "        labels.append(idx)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Dataset chargé :\")\n",
    "print(\"Images :\", data.shape)\n",
    "print(\"Labels :\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "effc81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data / 255.0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "382fbcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.venv\\mon_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 194ms/step - accuracy: 0.7303 - loss: 0.7353 - val_accuracy: 0.8537 - val_loss: 0.3788\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 194ms/step - accuracy: 0.8997 - loss: 0.2812 - val_accuracy: 0.9370 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - accuracy: 0.9064 - loss: 0.2494 - val_accuracy: 0.9309 - val_loss: 0.1802\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.9349 - loss: 0.1877 - val_accuracy: 0.9228 - val_loss: 0.1932\n",
      "Epoch 5/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 182ms/step - accuracy: 0.9461 - loss: 0.1481 - val_accuracy: 0.9350 - val_loss: 0.1962\n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 179ms/step - accuracy: 0.9522 - loss: 0.1331 - val_accuracy: 0.9370 - val_loss: 0.1760\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - accuracy: 0.9644 - loss: 0.0942 - val_accuracy: 0.9350 - val_loss: 0.1865\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 176ms/step - accuracy: 0.9812 - loss: 0.0537 - val_accuracy: 0.9370 - val_loss: 0.1753\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 177ms/step - accuracy: 0.9746 - loss: 0.0639 - val_accuracy: 0.9329 - val_loss: 0.1952\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - accuracy: 0.9934 - loss: 0.0276 - val_accuracy: 0.9411 - val_loss: 0.1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 classes\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "model.save(\"banana_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "612d6d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Résultat : pas_mur\n",
      "test2.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Résultat : pas_mur\n",
      "test3.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Résultat : mur\n",
      "test4.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Résultat : trop_mur\n",
      "test5.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Résultat : pas_mur\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model \n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "test_folder = \"img_test\"\n",
    "# model = load_model(\"banana_model.h5\")\n",
    "for filename in os.listdir(test_folder):\n",
    "    print(filename)\n",
    "    file_path = os.path.join(test_folder, filename)\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "    \n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    pred = model.predict(img)\n",
    "    class_idx = np.argmax(pred)\n",
    "\n",
    "    classes = [\"pas_mur\", \"mur\", \"trop_mur\"]\n",
    "    print(\"Résultat :\", classes[class_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833cf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossiers créés pour toutes les classes.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import json\n",
    "\n",
    "# DATASET_PATH = \"tomato_dataset/\"\n",
    "# IMG_FOLDER = os.path.join(DATASET_PATH, \"test\")\n",
    "# ANNOTATIONS = os.path.join(DATASET_PATH, \"test.json\")\n",
    "\n",
    "# OUTPUT = \"dataset_final/\"\n",
    "# os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "# # Charger le JSON\n",
    "# with open(ANNOTATIONS, \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# images_info = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "\n",
    "# # Charger les catégories\n",
    "# categories = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
    "\n",
    "# # Créer un dossier par classe\n",
    "# for cls_name in categories.values():\n",
    "#     os.makedirs(os.path.join(OUTPUT, cls_name), exist_ok=True)\n",
    "\n",
    "# print(\"Dossiers créés pour toutes les classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Extraction terminée !\n"
     ]
    }
   ],
   "source": [
    "# for ann in data[\"annotations\"]:\n",
    "\n",
    "#     # ID de l'image\n",
    "#     img_id = ann[\"image_id\"]\n",
    "\n",
    "#     if img_id not in images_info:\n",
    "#         continue\n",
    "\n",
    "#     img_info = images_info[img_id]\n",
    "#     img_name = img_info[\"file_name\"]\n",
    "#     img_path = os.path.join(IMG_FOLDER, img_name)\n",
    "\n",
    "#     # Vérifier que l’image existe\n",
    "#     if not os.path.exists(img_path):\n",
    "#         print(f\"⚠ Image manquante : {img_name}\")\n",
    "#         continue\n",
    "\n",
    "#     # Charger l'image\n",
    "#     img = cv2.imread(img_path)\n",
    "\n",
    "#     # Lire la bbox\n",
    "#     x, y, w, h = ann[\"bbox\"]\n",
    "#     x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "\n",
    "#     # Découpe (crop)\n",
    "#     crop = img[y:y+h, x:x+w]\n",
    "\n",
    "#     # Classe\n",
    "#     cls_id = ann[\"category_id\"]\n",
    "#     cls_name = categories[cls_id]\n",
    "\n",
    "#     # Nom du fichier enregistré\n",
    "#     save_name = f\"{img_name.replace('.jpg','')}_{ann['id']}.jpg\"\n",
    "#     save_path = os.path.join(OUTPUT, cls_name, save_name)\n",
    "\n",
    "#     cv2.imwrite(save_path, crop)\n",
    "\n",
    "# print(\"✔ Extraction terminée !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbbb7d",
   "metadata": {},
   "source": [
    "model de detection de tout les fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f591440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Lecture : banane\n",
      "⏳ Lecture : mangue\n",
      "Image ignorée: data_all/mangue\\trop_mur\\Capture d'écran 2025-11-25 141945.png\n",
      "Image ignorée: data_all/mangue\\trop_mur\\Capture d'écran 2025-11-25 142453.png\n",
      "Image ignorée: data_all/mangue\\trop_mur\\Capture d'écran 2025-11-25 142505.png\n",
      "⏳ Lecture : tomate\n",
      "\n",
      "=== Dataset chargé ===\n",
      "Nombre total d'images : 4927\n",
      "Profils des labels : (4927,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"data_all/\"\n",
    "ripeness_classes = [\"pas_mur\", \"mur\", \"trop_mur\"]\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Parcourir chaque fruit\n",
    "for fruit in os.listdir(DATASET_PATH):\n",
    "\n",
    "    fruit_path = os.path.join(DATASET_PATH, fruit)\n",
    "\n",
    "    # Vérifier que c'est bien un dossier\n",
    "    if not os.path.isdir(fruit_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"⏳ Lecture : {fruit}\")\n",
    "\n",
    "    # Parcourir les 3 niveaux de maturité\n",
    "    for label_idx, ripeness in enumerate(ripeness_classes):\n",
    "\n",
    "        category_path = os.path.join(fruit_path, ripeness)\n",
    "\n",
    "        if not os.path.isdir(category_path):\n",
    "            print(f\"⚠️ Sous-dossier manquant : {category_path}\")\n",
    "            continue\n",
    "\n",
    "        # Lire les images\n",
    "        for file in os.listdir(category_path):\n",
    "\n",
    "            img_path = os.path.join(category_path, file)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                print(\"Image ignorée:\", img_path)\n",
    "                continue\n",
    "\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            img = img / 255.0\n",
    "\n",
    "            data.append(img)\n",
    "            labels.append(label_idx)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"\\n=== Dataset chargé ===\")\n",
    "print(\"Nombre total d'images :\", data.shape[0])\n",
    "print(\"Profils des labels :\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea6286d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (3941, 128, 128, 3)\n",
      "Test : (986, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train :\", X_train.shape)\n",
    "print(\"Test :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "099f916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.venv\\mon_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m3,211,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,305,414</span> (12.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,305,414\u001b[0m (12.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,305,414</span> (12.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,305,414\u001b[0m (12.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b2f842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 214ms/step - accuracy: 0.8960 - loss: 0.2883 - val_accuracy: 0.9249 - val_loss: 0.2355\n",
      "Epoch 2/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 215ms/step - accuracy: 0.9198 - loss: 0.2176 - val_accuracy: 0.9320 - val_loss: 0.2094\n",
      "Epoch 3/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 217ms/step - accuracy: 0.9340 - loss: 0.1903 - val_accuracy: 0.9260 - val_loss: 0.2115\n",
      "Epoch 4/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 224ms/step - accuracy: 0.9373 - loss: 0.1678 - val_accuracy: 0.9422 - val_loss: 0.1781\n",
      "Epoch 5/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 230ms/step - accuracy: 0.9528 - loss: 0.1434 - val_accuracy: 0.9290 - val_loss: 0.2058\n",
      "Epoch 6/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 235ms/step - accuracy: 0.9541 - loss: 0.1230 - val_accuracy: 0.9300 - val_loss: 0.2245\n",
      "Epoch 7/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 236ms/step - accuracy: 0.9571 - loss: 0.1157 - val_accuracy: 0.9270 - val_loss: 0.2320\n",
      "Epoch 8/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 228ms/step - accuracy: 0.9703 - loss: 0.0831 - val_accuracy: 0.9260 - val_loss: 0.2933\n",
      "Epoch 9/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 244ms/step - accuracy: 0.9599 - loss: 0.1032 - val_accuracy: 0.8955 - val_loss: 0.3377\n",
      "Epoch 10/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 236ms/step - accuracy: 0.9663 - loss: 0.0873 - val_accuracy: 0.9371 - val_loss: 0.2469\n",
      "Epoch 11/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9830 - loss: 0.0496 - val_accuracy: 0.9189 - val_loss: 0.2982\n",
      "Epoch 12/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 273ms/step - accuracy: 0.9833 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.3080\n",
      "Epoch 13/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 256ms/step - accuracy: 0.9919 - loss: 0.0263 - val_accuracy: 0.9402 - val_loss: 0.3421\n",
      "Epoch 14/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 237ms/step - accuracy: 0.9937 - loss: 0.0170 - val_accuracy: 0.9351 - val_loss: 0.3781\n",
      "Epoch 15/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 241ms/step - accuracy: 0.9952 - loss: 0.0133 - val_accuracy: 0.9239 - val_loss: 0.5458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "model.save(\"fruit_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bfdd81ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Image : banane_mur.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Résultat : pas_mur\n",
      "-----\n",
      "Image : banane_mur1.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Résultat : trop_mur\n",
      "-----\n",
      "Image : banane_pas_mur.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Résultat : pas_mur\n",
      "-----\n",
      "Image : banane_pas_mur1.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Résultat : pas_mur\n",
      "-----\n",
      "Image : banane_trop_mur.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Résultat : trop_mur\n",
      "-----\n",
      "Image : omate_trop_mur1.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Résultat : trop_mur\n",
      "-----\n",
      "Image : tomate_mur.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Résultat : trop_mur\n",
      "-----\n",
      "Image : tomate_mur1.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Résultat : trop_mur\n",
      "-----\n",
      "Image : tomate_mur2.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Résultat : trop_mur\n",
      "-----\n",
      "Image : tomate_pas_mur.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Résultat : pas_mur\n",
      "-----\n",
      "Image : tomate_pas_mur1.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Résultat : pas_mur\n",
      "-----\n",
      "Image : tomate_pas_mur2.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Résultat : pas_mur\n",
      "-----\n",
      "Image : tomate_trop_mur.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Résultat : mur\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"fruit_model.h5\")\n",
    "\n",
    "test_folder = \"img_test\"\n",
    "\n",
    "classes = [\"pas_mur\", \"mur\", \"trop_mur\"]\n",
    "\n",
    "for filename in os.listdir(test_folder):\n",
    "\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(test_folder, filename)\n",
    "\n",
    "    print(\"-----\")\n",
    "    print(\"Image :\", filename)\n",
    "\n",
    "    img = cv2.imread(file_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(\"Erreur : image illisible\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    pred = model.predict(img)\n",
    "    class_idx = np.argmax(pred)\n",
    "\n",
    "    print(\"Résultat :\", classes[class_idx])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
